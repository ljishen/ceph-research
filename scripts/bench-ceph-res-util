#!/usr/bin/env bash
#
# Require bash version >= 4.4
#
# This script depends on passwordless ssh and passwordless sudo via the current
# user ($USER) on remote hosts.

set -euo pipefail

readonly SCRIPT_DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
# shellcheck source=./common.sh
. "$SCRIPT_DIR/common.sh"


usage() {
  cat <<EOF
Usage: $0 -m MON_IP -h OSD_HOST [-h OSD_HOST]... -s SCRIPT_FILE

Options:
  -m :         IP address for the clusterâ€™s monitor daemon.
  -h :         OSD host (e.g., -h host1 -h host2).
  -s :         the remote script (relative path to the remote_script/ceph_volume dir)
               for creating and querying ceph volumes on each host.

Defining the LVS_PROVISION=no can skip the logical volumes provisioning on hosts.

All SSH connections to the cluster hosts will use the user '\$USER' (current: $USER).

EOF
}

if (( $# < 2 )); then
  usage
  exit
fi


OSD_HOSTS=()
while getopts ":m:h:s:" option; do
  case $option in
    m  ) readonly MON_IP=$OPTARG ;;
    h  ) OSD_HOSTS+=("$OPTARG") ;;
    s  ) SCRIPT_FILE=$OPTARG ;;
    \? )
      usage
      common::err $(( ERR_STATUS_START + 1 )) "Invalid option: -$OPTARG"
      ;;
    :  )
      usage
      common::err $(( ERR_STATUS_START + 1 )) "Option -$OPTARG requires an argument."
      ;;
    *  )
      usage
      exit
  esac
done
shift "$(( OPTIND - 1 ))"

if [[ -z "${MON_IP:-}" ]]; then
  usage
  common::err $(( ERR_STATUS_START + 2 )) \
    "Please specify the IP address of the monitor using '-m'"
fi

if ! [[ "$MON_IP" =~ ^[[:digit:].]+$ ]]; then
  common::err $(( ERR_STATUS_START + 3 )) "Invalid IP address: $MON_IP"
fi

if (( "${#OSD_HOSTS[@]}" == 0 )); then
  usage
  common::err $(( ERR_STATUS_START + 2 )) "Please specify OSD_HOSTS using '-h'"
fi

if [[ -z "${SCRIPT_FILE:-}" ]]; then
  common::err $(( ERR_STATUS_START + 2 )) \
    "Please specify the SCRIPT_FILE using '-s'"
fi

if ! [[ -f "$SCRIPT_DIR/remote_script/ceph_volume/$SCRIPT_FILE" ]]; then
  common::err $(( ERR_STATUS_START + 3 )) \
    "Cannot find the script file '$SCRIPT_FILE' under the remote_script/ceph_volume dir"
fi

common::debug OSD_HOSTS: "$(common::print_array OSD_HOSTS)"


install_docker_sar() {
  common::stage "Check and install docker and sar..."

  local -ar all_hosts=( "$MON_IP" "${OSD_HOSTS[@]}" )
  local -a param_install_docker_hosts=() param_install_sar_hosts=()
  local host

  for host in "${all_hosts[@]}"; do
    if ! ssh "${SSH_COMM_OPTIONS[@]}" "$USER@$host" \
      command -v "docker" >/dev/null 2>&1; then
      param_install_docker_hosts+=( --host "$host" )
    fi

    if ! ssh "${SSH_COMM_OPTIONS[@]}" "$USER@$host" \
      command -v "sar" >/dev/null 2>&1; then
      param_install_sar_hosts+=( --host "$host" )
    fi
  done

  if (( ${#param_install_docker_hosts[@]} )); then
    "$SCRIPT_DIR"/parallel-docker-install \
      --env INFO_LEVEL=1 \
      "${param_install_docker_hosts[@]}"
  fi

  if (( ${#param_install_sar_hosts[@]} )); then
    CMD_MODE=false "$SCRIPT_DIR"/parallel-exec-script \
      --script=install/sysstat \
      --env INFO_LEVEL=1 \
      "${param_install_sar_hosts[@]}"
  fi
}
install_docker_sar

prepare_param_hosts() {
  local -n _param_hosts=$1
  local host

  for host in "${OSD_HOSTS[@]}"; do
    _param_hosts+=( --host "$host" )
  done
}

# shellcheck source=./remote_script/ceph_volume/interface.sh
. "$SCRIPT_DIR"/remote_script/ceph_volume/interface.sh
create_ceph_lvs() {
  common::stage "Create logical volumes on OSD hosts..."

  local -a param_hosts
  prepare_param_hosts param_hosts

  "$SCRIPT_DIR"/parallel-exec-script \
    --script ceph_volume/"$SCRIPT_FILE" \
    --env INFO_LEVEL=1 \
    --env CEPH_VOLUME_OPERATION="$CEPH_VOLUME_OPERATION_CREATE" \
    "${param_hosts[@]}"
}
if [[ "${LVS_PROVISION:-yes}" != "no" ]]; then
  create_ceph_lvs
fi


# shellcheck source=./remote_script/service/interface.sh
. "$SCRIPT_DIR"/remote_script/service/interface.sh
start_sys_activity_daemons() {
  common::stage "Launch system activity collector daemons on cluster hosts..."

  local -a param_hosts=( --host "$MON_IP" )
  prepare_param_hosts param_hosts

  "$SCRIPT_DIR"/parallel-exec-script \
    --script service/sar \
    --env INFO_LEVEL=1 \
    --env SERVICE_OPERATION="$SERVICE_OPERATION_RESTART" \
    "${param_hosts[@]}"
}

stop_sys_activity_daemons() {
  common::stage "Stop system activity collector daemons and gather results..."
  local -r sys_activity_data_dir="$OUTPUT_DIR"/sys_activity
  mkdir --parents "$sys_activity_data_dir"

  local -ar all_hosts=( "$MON_IP" "${OSD_HOSTS[@]}" )
  local host remote_output_file
  for host in "${all_hosts[@]}"; do
    INFO_LEVEL=1
    common::info "Backing up system activity information from $host"

    remote_output_file="$(
      "$SCRIPT_DIR"/parallel-exec-script \
        --script service/sar \
        --env INFO_LEVEL=1 \
        --env SERVICE_OPERATION="$SERVICE_OPERATION_QUERY" \
        --host "$host" | common::parse_remote_out
    )"

    "$SCRIPT_DIR"/parallel-exec-script \
      --script service/sar \
      --env INFO_LEVEL=1 \
      --env SERVICE_OPERATION="$SERVICE_OPERATION_STOP" \
      --host "$host"

    local local_output_file
    if [[ "$host" == "$MON_IP" ]]; then
      local_output_file=mon.$host.dat
    else
      local_output_file=osd.$host.dat
    fi

    trace_on
    scp -C "${SSH_COMM_OPTIONS[@]}" -p \
      "$host":"$remote_output_file" \
      "$sys_activity_data_dir/$local_output_file"
    trace_off
  done
}

shell_cmd() {
  {
    local -ir is_set_x=$(common::is_set_x)
    # temporarily turn off tracing to avoid redundant output
    if (( is_set_x == 0 )); then
      trace_off
    fi
  } 2>/dev/null

  if [[ -z "${CEPH_CLUSTER_KEYRING_PATH}" ]]; then
    common::err $(( ERR_STATUS_START + 4 )) \
      "Fail to read the Ceph cluster's keyring file."
  fi

  echo "$SCRIPT_DIR/parallel-cephadm shell" \
    "--keyring $CEPH_CLUSTER_KEYRING_PATH" \
    "--"

  if (( is_set_x == 0 )); then
    trace_on
  fi
}

deploy_ceph() {
  local -a param_host_osds
  local host host_lvs joined

  for host in "${OSD_HOSTS[@]}"; do
    host_lvs=("$(
      "$SCRIPT_DIR"/parallel-exec-script \
        --script ceph_volume/"$SCRIPT_FILE" \
        --env CEPH_VOLUME_OPERATION="$CEPH_VOLUME_OPERATION_QUERY" \
        --host "$host" | common::parse_remote_out
    )")

    printf -v joined '%s,' "${host_lvs[@]}"
    param_host_osds+=( -o "$host:${joined%,}" )
  done

  local ceph_deploy_output
  ceph_deploy_output="$(
    "$SCRIPT_DIR"/ceph-deploy -m "$MON_IP" "${param_host_osds[@]}" \
      2>&1 | tee /dev/tty
  )"

  CEPH_CLUSTER_FSID="$(
    grep --only-matching --perl-regexp "Cluster fsid: \K[[:alnum:]-]+" \
      <<< "$ceph_deploy_output"
  )"

  CEPH_CLUSTER_KEYRING_PATH="$(
      grep --only-matching --perl-regexp "Wrote keyring to \K.+" \
      <<< "$ceph_deploy_output"
  )"

  INFO_LEVEL=1 common::info "Sleep for 15 seconds"
  sleep 15
}

load_cluster_data() {
  local -ir pool_size=$1 num_pgs=$2 object_size_bytes=$3

  local -r pool_name="bench_failure_management_resource_utilization"
  local -i data_size_per_osd=$(( object_size_bytes * 1024 * 1024 / 2 )) \
           data_size_per_osd_max=$(( 10 * 1024 * 1024 * 1024 ))

  data_size_per_osd=$(( data_size_per_osd > data_size_per_osd_max \
    ? data_size_per_osd_max : data_size_per_osd ))

  common::stage "Prepare data on the cluster..."

  INFO_LEVEL=1 common::info "Set pool attributes"

  INFO_LEVEL=2
  common::info "Create a replicated pool '$pool_name' with $num_pgs placement groups"
  trace_on
  $(shell_cmd) ceph osd pool create "$pool_name" "$num_pgs" "$num_pgs" replicated
  trace_off

  common::info "Disable placement groups autoscaling"
  trace_on
  $(shell_cmd) ceph osd pool set "$pool_name" pg_autoscale_mode off
  trace_off

  common::info "Set the number of replicas for objects in the pool to $pool_size"
  trace_on
  $(shell_cmd) ceph osd pool set "$pool_name" size "$pool_size"
  trace_off

  common::info "Set the minimum number of replicas required for I/O to 1"
  trace_on
  $(shell_cmd) ceph osd pool set "$pool_name" min_size 1
  trace_off

  common::info "Set the NOSCRUB flag"
  trace_on
  $(shell_cmd) ceph osd pool set "$pool_name" noscrub 1
  trace_off

  common::info "Set the NODEEP_SCRUB flag"
  trace_on
  $(shell_cmd) ceph osd pool set "$pool_name" nodeep-scrub 1
  trace_off

  common::info "Show details of pools"
  trace_on
  $(shell_cmd) ceph osd pool ls detail
  trace_off

  INFO_LEVEL=1 common::info "Loading objects" \
    "(total data size: $(( data_size_per_osd * ${#OSD_HOSTS[@]} / 1024 / 1024 / 1024 )) GB)"
  # -b op_size
  # -O object_size
  #   https://github.com/ceph/ceph/blob/v16.0.0/src/tools/rados/rados.cc#L183
  trace_on
  $(shell_cmd) rados bench 99999999 write \
    --pool "$pool_name" \
    -b $(( object_size_bytes )) \
    -O $(( object_size_bytes )) \
    --max-objects $(( data_size_per_osd * ${#OSD_HOSTS[@]} / object_size_bytes )) \
    --concurrent-ios $(( ${#OSD_HOSTS[@]} * 256 )) \
    --show-time \
    --write-object \
    --write-omap \
    --write-xattr \
    --no-cleanup
  trace_off

  common::info "Sleep for 10 seconds"
  sleep 10

  common::info "Show OSD utilization"
  trace_on
  $(shell_cmd) ceph osd df tree
  trace_off
}

rm_osds() {
  if [[ -z "${CEPH_CLUSTER_FSID:-}" ]]; then
    common::err $(( ERR_STATUS_START + 4 )) \
      "Unable to read the cluster fsid."
  fi

  local -ir num_rm=$1
  local -i idx

  common::stage "Removing $num_rm OSDs from the cluster"
  for (( idx = 0; idx < ${#OSD_HOSTS[@]}; idx++ )); do
    if (( num_rm == idx )); then
      break
    fi

    INFO_LEVEL=1 common::info "Removing 'osd.$idx' from host '${OSD_HOSTS[$idx]}'"
    "$SCRIPT_DIR"/parallel-cephadm \
      --host "${OSD_HOSTS[$idx]}" \
      rm-daemon \
      --name osd."$idx" \
      --fsid "$CEPH_CLUSTER_FSID" \
      --force \
      --force-delete-data
  done
}

tear_down_ceph() {
  if [[ -z "${CEPH_CLUSTER_FSID:-}" ]]; then
    common::err $(( ERR_STATUS_START + 4 )) \
      "Unable to read the cluster fsid."
  fi

  local -a param_hosts=( --host "$MON_IP" )
  prepare_param_hosts param_hosts

  common::stage "Tearing down the Ceph cluster (fsid: $CEPH_CLUSTER_FSID)"
  "$SCRIPT_DIR"/parallel-cephadm "${param_hosts[@]}" \
    rm-cluster \
    --force \
    --fsid "$CEPH_CLUSTER_FSID"

  INFO_LEVEL=1 common::info "Sleep for 10 seconds"
  sleep 10
}

get_suggested_pg_count() {
  # Logic behind PG Count
  # See https://ceph.com/pgcalc/
  #     https://ceph.com/pgcalc_assets/pgcalc.js (function updatePGCount)
  #     https://docs.ceph.com/en/latest/rados/operations/placement-groups/#choosing-number-of-placement-groups
  awk -v pool_size="$1" -v num_osds="$2" -v target_pgs_per_osd="${3:-100}" '
    function nearestpower2(num) {
      tmp = 2 ^ int(log(num) / log(2))
      if (tmp < num * (1 - 0.25))
        tmp *= 2
      return tmp
    }

    BEGIN {
      min_value = nearestpower2(int(num_osds / pool_size) + 1)
      if (min_value < num_osds)
        min_value *= 2

      calc_value = nearestpower2(int(target_pgs_per_osd * num_osds / pool_size))

      print (min_value > calc_value ? min_value : calc_value)
    }
  '
}


bench_replicated_pool() {
  local -ar object_size_bytes_arr=(
    $(( 4 * 1024 ))
    $(( 32 * 1024 ))
    $(( 256 * 1024 ))
    $(( 2048 * 1024 ))
    $(( 16384 * 1024 ))
  )

  local -a pool_size_arr
  IFS=' ' read -ra pool_size_arr <<< "$(seq -s ' ' 1 "${#OSD_HOSTS[@]}")"

  local -i pool_size suggested_pg_count
  for pool_size in "${pool_size_arr[@]}"; do
    suggested_pg_count=$(
      get_suggested_pg_count "$pool_size" ${#OSD_HOSTS[@]})
    common::debug suggested_pg_count: "$suggested_pg_count" \
      "(pool_size=$pool_size, num_osds=${#OSD_HOSTS[@]})"

    local -a num_pgs_arr=(
      $(( suggested_pg_count / 4 ))
      $(( suggested_pg_count / 2 ))
      suggested_pg_count
      $(( suggested_pg_count * 2 ))
      $(( suggested_pg_count * 4 ))
    )

    local -i num_pgs
    for num_pgs in "${num_pgs_arr[@]}"; do
      local -i object_size_bytes
      for object_size_bytes in "${object_size_bytes_arr[@]}"; do
        local -i num_rm_osds
        for (( num_rm_osds = 1; num_rm_osds < ${#OSD_HOSTS[@]}; num_rm_osds++ )); do

          (( BENCHMARK_ROUND += 1 ))
          printf "\\n\\n\\033[1;7;39;49m[%s][RUNNING][ROUND %d/%d] %s, %s, %s, %s\\033[0m\\n\\n" \
            "$(date --iso-8601=ns)" \
            "$BENCHMARK_ROUND" \
            $(( ${#pool_size_arr[@]} * ${#num_pgs_arr[@]} * ${#object_size_bytes_arr[@]} * (${#OSD_HOSTS[@]} - 1) )) \
            "pool_size=$pool_size (${pool_size_arr[0]}..${pool_size_arr[-1]})" \
            "num_pgs=$num_pgs (${num_pgs_arr[0]}..${num_pgs_arr[-1]})" \
            "object_size_bytes=$object_size_bytes (${object_size_bytes_arr[0]}..${object_size_bytes_arr[-1]})" \
            "num_rm_osds=$num_rm_osds (1..$(( ${#OSD_HOSTS[@]} - 1 )))"

          deploy_ceph

          load_cluster_data "$pool_size" "$num_pgs" "$object_size_bytes"

          rm_osds "$num_rm_osds"

          # wait for data collection...
          echo "Waiting for data collection!!!!!!"
          sleep 30

          tear_down_ceph
        done
      done
    done
  done
}

bench_erasure_coded_pool() {
  common::err $(( ERR_STATUS_START + 999 )) \
    "Function not implemented yet!"
}


main() {
  OUTPUT_DIR="$PWD/results"
  BENCHMARK_ROUND=0

  start_sys_activity_daemons
  bench_replicated_pool
  stop_sys_activity_daemons
}
main
